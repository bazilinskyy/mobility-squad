---
layout: project
year: 2024
title: "In-vehicle Agent"
authors:
  - name: Xingjian Zeng
    website: https://www.linkedin.com/in/xingjian-zeng-596a29213/
coaches:
  - name: Shadab Alam
    website: https://nl.linkedin.com/in/md-shadab-alam-03b8251aa
  - name: Pavlo Bazilinskyy
    website: https://bazilinskyy.github.io
categories: project
company:
  - name: na
    website: na
tags: [in-vehicle agent, robot-like agent, gesture, facial expression, voice interaction,]
image: 2024-robot-iva-1.jpg
short: Robot-like in-vehicle agent with emotional feedback.
---

## Description
With rapid development of automotive technology and artificial intelligence, in-vehicle agents have large potential to solve the challenges raised in automated driving context through literature review. Thus, a robot-like in-vehicle agent is developed to explore the advantages and challenges of comparing gestures and voice interaction with facial expressions and voice interaction in SAE Level 3 automated driving scenarios. And an experiment is conducted to evaluate the prototype. Results showed that both interactions of facial expressions and gestures can reduce workload, increase usefulness, satisfaction and trust. However, gestures seem to be more functional and more preferred by the driver while facial expressions seem to be more emotional and preferred by passengers. Furthermore, gestures are easier to notice but hard to understand independently and facial expressions are just the opposite. 

<div class="project-image">
  <img src="/assets/img/2024-robot-iva-2.jpg">
</div>
<div class="project-image">
  <img src="/assets/img/2024-robot-iva-3.jpg">
</div>

<!-- ## Video
<iframe style="display:inline-block; border:0px solid #FFF; width: 100%; height: 358px" src="https://www.youtube.com/embed/aYPmEhbB8jk?playlist=aYPmEhbB8jk&loop=1&autoplay=1&mute=1" frameborder="0" allowfullscreen></iframe> -->
